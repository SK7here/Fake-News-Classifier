{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To work with nd-arrays\n",
    "import numpy as np\n",
    "\n",
    "#To work with data structures\n",
    "import pandas as pd\n",
    "\n",
    "#To plot graphs within terminal(for Jupyter Notebooks only)\n",
    "%matplotlib inline\n",
    "\n",
    "#To compute accuracy for models\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#To split dataset into training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importing Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Preprocessing Text documents(articles)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#To build Convolution Neural Network\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "#To plot graphs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining constants for easy usage\n",
    "MAX_SEQUENCE_LENGTH = 5000\n",
    "MAX_NUM_WORDS = 25000\n",
    "TEST_SPLIT = 0.2\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "TEXT_DATA = 'data/fake_or_real_news.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function defined to evaluate models\n",
    "def evaluate_model(pred_func, X_train, y_train, X_test, y_test):\n",
    "    #Training Accuracy\n",
    "    y_predict_train = pred_func(X_train)\n",
    "    train_acc = accuracy_score(y_train,y_predict_train)\n",
    "    \n",
    "    #Testing Accuracy\n",
    "    y_predict_test = pred_func(X_test)\n",
    "    test_acc = accuracy_score(y_test,y_predict_test)\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE\n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE\n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL\n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE\n",
       "4  It's primary day in New York and front-runners...  REAL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading dataset\n",
    "df = pd.read_csv(TEXT_DATA)\n",
    "#Dropping variables that are irrelevant to our study\n",
    "df.drop(labels=['id','title'], axis='columns', inplace=True)\n",
    "#Filtering out articles with no text\n",
    "mask = list(df['text'].apply(lambda x: len(x) > 0))\n",
    "df = df[mask]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6335 texts.\n",
      "Found 6335 labels.\n"
     ]
    }
   ],
   "source": [
    "#Ensuring all text samples have their labels\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "print('Found %s texts.' %texts.shape)\n",
    "print('Found %s labels.' %labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum number of words in an article\n",
      "20897\n",
      "\n",
      "Histogram plot for articles upto 5000 words\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finding word count of each article\n",
    "text_lengths = texts.apply(lambda x: len(x.split(\" \")))\n",
    "print(\"\\nMaximum number of words in an article\")\n",
    "print(text_lengths.max())\n",
    "\n",
    "#Histogram plot for word count\n",
    "print(\"\\nHistogram plot for articles upto 5000 words\")\n",
    "plt.hist(text_lengths, bins=[0,500,1000,1500,2000,2500,3000,3500,4000,4500,5000])\n",
    "plt.ylabel(\"Article count\")\n",
    "plt.xlabel(\"No of words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method I - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Count Vectorization\n",
      "\n",
      "      daniel  greenfield  shillman  journalism  fellow  freedom  center  new  \\\n",
      "0          0           0         0           0       0        0       0    0   \n",
      "1          0           0         0           0       0        0       0    0   \n",
      "2          0           0         0           0       0        0       0    0   \n",
      "3          0           1         0           0       0        0       0    0   \n",
      "4          0           0         0           0       0        0       0    0   \n",
      "5          0           0         0           0       0        0       0    0   \n",
      "6          0           0         0           0       0        0       0    0   \n",
      "7          0           0         0           0       0        0       0    0   \n",
      "8          0           0         0           0       0        0       0    0   \n",
      "9          0           1         0           0       0        0       0    0   \n",
      "10         0           0         0           0       0        0       0    0   \n",
      "11         0           0         0           0       0        0       0    0   \n",
      "12         0           0         0           0       0        0       0    0   \n",
      "13         0           0         0           0       0        0       0    0   \n",
      "14         0           0         0           0       0        0       0    0   \n",
      "15         0           0         0           0       0        0       0    0   \n",
      "16         0           0         0           0       0        0       0    0   \n",
      "17         0           0         0           0       0        0       0    0   \n",
      "18         0           0         0           0       0        0       0    0   \n",
      "19         0           0         0           0       0        0       0    0   \n",
      "20         0           0         0           0       0        0       0    0   \n",
      "21         0           0         0           0       0        0       0    0   \n",
      "22         0           1         0           0       0        0       0    0   \n",
      "23         0           0         0           0       0        0       0    0   \n",
      "24         0           0         0           0       0        0       0    0   \n",
      "25         0           0         0           0       0        0       0    0   \n",
      "26         0           0         0           0       0        0       0    0   \n",
      "27         0           0         0           0       0        0       0    0   \n",
      "28         0           0         0           0       0        0       0    0   \n",
      "29         0           0         0           0       0        0       0    0   \n",
      "...      ...         ...       ...         ...     ...      ...     ...  ...   \n",
      "6305       0           0         0           0       0        0       0    0   \n",
      "6306       0           0         0           0       0        0       0    0   \n",
      "6307       0           0         0           0       0        0       0    0   \n",
      "6308       0           0         0           0       0        0       0    0   \n",
      "6309       0           0         0           0       0        0       0    0   \n",
      "6310       0           0         0           0       0        0       0    0   \n",
      "6311       0           0         0           0       0        0       0    0   \n",
      "6312       0           0         0           0       0        0       0    0   \n",
      "6313       0           1         0           0       0        0       0    0   \n",
      "6314       0           0         0           0       0        0       0    0   \n",
      "6315       0           0         0           0       0        0       0    0   \n",
      "6316       0           0         0           0       0        0       0    0   \n",
      "6317       0           0         0           0       0        0       0    0   \n",
      "6318       0           0         0           0       0        0       0    0   \n",
      "6319       0           0         0           0       0        0       0    0   \n",
      "6320       0           0         0           0       0        0       0    0   \n",
      "6321       0           0         0           0       0        0       0    0   \n",
      "6322       0           0         0           0       0        0       0    0   \n",
      "6323       0           1         0           0       0        0       0    0   \n",
      "6324       0           0         0           0       0        0       0    0   \n",
      "6325       0           0         0           0       0        0       0    0   \n",
      "6326       0           0         0           0       0        0       0    0   \n",
      "6327       0           0         0           0       0        0       0    0   \n",
      "6328       0           0         0           0       0        0       0    0   \n",
      "6329       0           0         0           0       0        0       0    0   \n",
      "6330       0           1         0           0       0        0       0    0   \n",
      "6331       0           0         0           0       0        0       0    0   \n",
      "6332       0           1         0           0       0        0       0    0   \n",
      "6333       0           1         0           0       0        0       0    0   \n",
      "6334       0           0         0           0       0        0       0    0   \n",
      "\n",
      "      york  writer  ...  kneader  assaf  kneaded  mixer  kalev  dredging  \\\n",
      "0        0       0  ...        0      0        0      0      0         0   \n",
      "1        0       0  ...        0      0        0      0      0         0   \n",
      "2        0       0  ...        0      0        0      0      0         0   \n",
      "3        0       0  ...        0      0        0      0      0         0   \n",
      "4        0       0  ...        0      0        0      0      0         0   \n",
      "5        0       0  ...        0      0        0      0      0         0   \n",
      "6        0       0  ...        0      0        0      0      0         0   \n",
      "7        0       0  ...        0      0        0      0      0         0   \n",
      "8        0       0  ...        0      0        0      0      0         0   \n",
      "9        0       0  ...        0      0        0      0      0         0   \n",
      "10       0       0  ...        0      0        0      0      0         0   \n",
      "11       0       0  ...        0      0        0      0      0         0   \n",
      "12       0       0  ...        0      0        0      0      0         0   \n",
      "13       0       0  ...        0      0        0      0      0         0   \n",
      "14       0       0  ...        0      0        0      0      0         0   \n",
      "15       0       0  ...        0      0        0      0      0         0   \n",
      "16       0       0  ...        0      0        0      0      0         0   \n",
      "17       0       0  ...        0      0        0      0      0         0   \n",
      "18       0       0  ...        0      0        0      0      0         0   \n",
      "19       0       0  ...        0      0        0      0      0         0   \n",
      "20       0       0  ...        0      0        0      0      0         0   \n",
      "21       0       0  ...        0      0        0      0      0         0   \n",
      "22       0       0  ...        0      0        0      0      0         0   \n",
      "23       0       0  ...        0      0        0      0      0         0   \n",
      "24       0       0  ...        0      0        0      0      0         0   \n",
      "25       0       0  ...        0      0        0      0      0         0   \n",
      "26       0       0  ...        0      0        0      0      0         0   \n",
      "27       0       0  ...        0      0        0      0      0         0   \n",
      "28       0       0  ...        0      0        0      0      0         0   \n",
      "29       0       0  ...        0      0        0      0      0         0   \n",
      "...    ...     ...  ...      ...    ...      ...    ...    ...       ...   \n",
      "6305     0       0  ...        0      0        0      0      0         0   \n",
      "6306     0       0  ...        0      0        0      0      0         0   \n",
      "6307     0       0  ...        0      0        0      0      0         0   \n",
      "6308     0       0  ...        0      0        0      0      0         0   \n",
      "6309     0       0  ...        0      0        0      0      0         0   \n",
      "6310     0       0  ...        0      0        0      0      0         0   \n",
      "6311     0       0  ...        0      0        0      0      0         0   \n",
      "6312     0       0  ...        0      0        0      0      0         0   \n",
      "6313     0       0  ...        0      0        0      0      0         0   \n",
      "6314     0       0  ...        0      0        0      0      0         0   \n",
      "6315     0       0  ...        0      0        0      0      0         0   \n",
      "6316     0       0  ...        0      0        0      0      0         0   \n",
      "6317     0       0  ...        0      0        0      0      0         0   \n",
      "6318     0       0  ...        0      0        0      0      0         0   \n",
      "6319     0       0  ...        0      0        0      0      0         0   \n",
      "6320     0       0  ...        0      0        0      0      0         0   \n",
      "6321     0       0  ...        0      0        0      0      0         0   \n",
      "6322     0       0  ...        0      0        0      0      0         0   \n",
      "6323     0       0  ...        0      0        0      0      0         0   \n",
      "6324     0       0  ...        0      0        0      0      0         0   \n",
      "6325     0       0  ...        0      0        0      0      0         0   \n",
      "6326     0       0  ...        0      0        0      0      0         0   \n",
      "6327     0       0  ...        0      0        0      0      0         0   \n",
      "6328     0       0  ...        0      0        0      0      0         0   \n",
      "6329     0       0  ...        0      0        0      0      0         0   \n",
      "6330     0       0  ...        0      0        0      0      0         0   \n",
      "6331     0       0  ...        0      0        0      0      0         0   \n",
      "6332     0       0  ...        0      0        0      0      0         0   \n",
      "6333     0       0  ...        0      0        0      0      0         0   \n",
      "6334     0       0  ...        0      0        0      0      0         0   \n",
      "\n",
      "      partakers  dexter  wryly  comported  \n",
      "0             0       0      0          0  \n",
      "1             0       0      0          0  \n",
      "2             0       0      0          0  \n",
      "3             0       0      0          0  \n",
      "4             0       0      0          0  \n",
      "5             0       0      0          0  \n",
      "6             0       0      0          0  \n",
      "7             0       0      0          0  \n",
      "8             0       0      0          0  \n",
      "9             0       0      0          0  \n",
      "10            0       0      0          0  \n",
      "11            0       0      0          0  \n",
      "12            0       0      0          0  \n",
      "13            0       0      0          0  \n",
      "14            0       0      0          0  \n",
      "15            0       0      0          0  \n",
      "16            0       0      0          0  \n",
      "17            0       0      0          0  \n",
      "18            0       0      0          0  \n",
      "19            0       0      0          0  \n",
      "20            0       0      0          0  \n",
      "21            0       0      0          0  \n",
      "22            0       0      0          0  \n",
      "23            0       0      0          0  \n",
      "24            0       0      0          0  \n",
      "25            0       0      0          0  \n",
      "26            0       0      0          0  \n",
      "27            0       0      0          0  \n",
      "28            0       0      0          0  \n",
      "29            0       0      0          0  \n",
      "...         ...     ...    ...        ...  \n",
      "6305          0       0      0          0  \n",
      "6306          0       0      0          0  \n",
      "6307          0       0      0          0  \n",
      "6308          0       0      0          0  \n",
      "6309          0       0      0          0  \n",
      "6310          0       0      0          0  \n",
      "6311          0       0      0          0  \n",
      "6312          0       0      0          0  \n",
      "6313          0       0      0          0  \n",
      "6314          0       0      0          0  \n",
      "6315          0       0      0          0  \n",
      "6316          0       0      0          0  \n",
      "6317          0       0      0          0  \n",
      "6318          0       0      0          0  \n",
      "6319          0       0      0          0  \n",
      "6320          0       0      0          0  \n",
      "6321          0       0      0          0  \n",
      "6322          0       0      0          0  \n",
      "6323          0       0      0          0  \n",
      "6324          0       0      0          0  \n",
      "6325          0       0      0          0  \n",
      "6326          0       0      0          0  \n",
      "6327          0       0      0          0  \n",
      "6328          0       0      0          0  \n",
      "6329          0       0      0          0  \n",
      "6330          0       0      0          0  \n",
      "6331          0       0      0          0  \n",
      "6332          0       0      0          0  \n",
      "6333          0       0      0          0  \n",
      "6334          0       0      0          0  \n",
      "\n",
      "[6335 rows x 39271 columns]\n"
     ]
    }
   ],
   "source": [
    "# set up vector models for training and testing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# data vectorizer\n",
    "    #max_df/min_df = int->no of documents ; float->percentage among total documents\n",
    "    #stop_words = english-> inbulit stop words list for english is used\n",
    "    #binary = True-> if a word occurs even once, assigns '1'\n",
    "    #analyzer = features are taken as words    \n",
    "vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             binary = True, \n",
    "                             min_df = 2,\n",
    "                             stop_words='english')\n",
    "#Vectorizer is fit for the dataset\n",
    "docarray = vectorizer.fit_transform(texts).toarray()\n",
    "#Displaying output of Count Vectorization as a dataframe\n",
    "    #vectorizer.vocabulary_ -> returns feature names(words)\n",
    "docterm = pd.DataFrame(docarray, columns=vectorizer.vocabulary_)\n",
    "print(\"\\nAfter Count Vectorization\\n\")\n",
    "print(docterm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test data\n",
    "    #One hot encoding the categorical dependent labels\n",
    "docterm_train, docterm_test, y_train, y_test = train_test_split(docterm, labels.apply(lambda x: 0 if x == 'FAKE' else 1), test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 93.65\n",
      "Testing Accuracy: 90.21\n"
     ]
    }
   ],
   "source": [
    "#Creating a Multinomial Naive Bayes model\n",
    "    #Calculates probability of a word occuring in each class(FAKE/REAL) based on given input\n",
    "    #Considers each word as an independent feature\n",
    "model = MultinomialNB()\n",
    "model.fit(docterm_train, y_train)\n",
    "\n",
    "#Computing Training and validation accuracy\n",
    "train_acc, test_acc = evaluate_model(model.predict, docterm_train, y_train, docterm_test, y_test)\n",
    "print(\"Training Accuracy: {:.2f}\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method II - Convolutional DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To keep only \"MAX_NUM_WORDS - 25000\" most common words\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "#Creating Vocabulary index based on word frequency; lower the index, higher the frequency\n",
    "tokenizer.fit_on_texts(texts)\n",
    "#Replacing words with corresponding word index taken from fit_on_texts\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"\\nUnique words found in the dataset are listed below arranged according to most occurence frequency\\n\")\n",
    "print(word_index)\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "\n",
    "'''To make each sequence in list to have \"MAX_SEQUENCE_LENGTH - 5000\" values by padding 0's in front of each sequence \n",
    "and truncating words in front if sequence has over 5000 values'''\n",
    "    \n",
    "data = pad_sequences(sequences, \n",
    "                     maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                     padding='pre', \n",
    "                     truncating='pre')\n",
    "\n",
    "print('Found {} unique tokens.' .format(len(word_index)))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test data\n",
    "    #One hot encoding the categorical dependent labels\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, \n",
    "                                                  labels.apply(lambda x: 0 if x == 'FAKE' else 1), \n",
    "                                                  test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the CNN model\n",
    "model = Sequential(\n",
    "    [\n",
    "        #representing text as continous vector represenrations and perform word embeddings - find similar words\n",
    "        layers.Embedding(num_words, #Size of vocabulary\n",
    "                         EMBEDDING_DIM,\n",
    "                         input_length = MAX_SEQUENCE_LENGTH, #Length of each sequence(article)\n",
    "                         trainable=True), #To update weights during training)\n",
    "        \n",
    "        #Conv1D useful for NLP\n",
    "        #number of output filters = 128 \n",
    "        #window size = 5; 5 words are considered at a time\n",
    "        layers.Conv1D(128, 5, activation='relu'),\n",
    "        \n",
    "        #Pooling done to reduce spatial size of representation and reduce computations in neural networks\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "        #Forming a fully connected hidden layer\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        #Forming a fully connected output layer\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop', #restricts oscillations\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "train_acc, test_acc = evaluate_model(model.predict(),\n",
    "                                     x_train, \n",
    "                                     y_train, \n",
    "                                     x_val, \n",
    "                                     y_val)\n",
    "print(\"Training Accuracy: {:.2f}\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}\".format(test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
